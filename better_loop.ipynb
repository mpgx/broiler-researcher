{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c23fa8a2-b64e-49fb-a03d-d11b732dbc27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import statistics\n",
    "from skimage.io import imread, imsave\n",
    "from skimage import feature\n",
    "from scipy import ndimage as ndi\n",
    "from sklearn.cluster import KMeans\n",
    "from skimage import img_as_ubyte\n",
    "from skimage import (filters,\n",
    "                     morphology,\n",
    "                     exposure,\n",
    "                     measure)\n",
    "\n",
    "from commons import (crop_image_box, \n",
    "                     binarize_image,\n",
    "                     plot_grid_images, \n",
    "                     build_volume_from_directory,\n",
    "                     crop_image_reduce_errors,\n",
    "                     rule_of_three)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f136de25-fd82-4903-9906-89929f00cb1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_kmeans(img, k_clusters=3):\n",
    "    return KMeans(random_state=1,\n",
    "                  n_clusters=k_clusters,\n",
    "                  init='k-means++'\n",
    "                  ).fit(img.reshape((-1, 1))).labels_.reshape(img.shape)\n",
    "\n",
    "\n",
    "def find_center_mask(image_bin):\n",
    "    \"\"\"\n",
    "        Retona o centro da imagem\n",
    "    \"\"\"\n",
    "\n",
    "    props, *_ = measure.regionprops(\n",
    "        measure.label(image_bin)\n",
    "    )\n",
    "\n",
    "    x, y = props.centroid\n",
    "\n",
    "    return int(x), int(y)\n",
    "\n",
    "\n",
    "def find_perfect_cluster(mask):\n",
    "    \"\"\"\n",
    "        Função especial para o kmeans\n",
    "    \"\"\"\n",
    "    max_area = 0\n",
    "    max_area_index = 0\n",
    "\n",
    "    for index, props in enumerate(measure.regionprops(mask)):\n",
    "        if props.area >= max_area:\n",
    "            max_area = props.area\n",
    "            max_area_index = index + 1\n",
    "    return max_area_index\n",
    "\n",
    "\n",
    "def find_bighest_cluster_area(clusters):\n",
    "    \"\"\"\n",
    "        Essa função deve receber uma imagem segmentada (Clusters)\n",
    "        Retorna a área do maior cluster\n",
    "    \"\"\"\n",
    "    regions = measure.regionprops(clusters)\n",
    "\n",
    "    def area(item): return item.area\n",
    "\n",
    "    return max(map(area, regions))\n",
    "\n",
    "\n",
    "def find_best_larger_cluster(image_mask):\n",
    "\n",
    "    clusters = image_mask.copy()\n",
    "\n",
    "    if statistics.mode(clusters.flatten()):\n",
    "        clusters = np.invert(clusters)\n",
    "\n",
    "    clusters_labels = measure.label(clusters, background=0)\n",
    "\n",
    "    cluster_size = find_bighest_cluster_area(clusters_labels)\n",
    "\n",
    "    return morphology.remove_small_objects(\n",
    "        clusters,\n",
    "        min_size=(cluster_size-1),\n",
    "        connectivity=8\n",
    "    )\n",
    "\n",
    "\n",
    "def segmentation_roi(image):\n",
    "    \n",
    "    # Aplica K-means na imagem\n",
    "    clusters = apply_kmeans(image, k_clusters=2)\n",
    "\n",
    "    # Ecolhe melhor da segmentação Kmeans\n",
    "    best_cluster = find_perfect_cluster(clusters)\n",
    "\n",
    "    # Encontra maior cluster a mascara e remove as menores\n",
    "    return find_best_larger_cluster((clusters == best_cluster))\n",
    "\n",
    "    \n",
    "def segmentation_mask_v2(image, background):\n",
    "    \n",
    "    image_eq = np.subtract(exposure.equalize_hist(image),\n",
    "                           exposure.equalize_hist(background))\n",
    "    \n",
    "    image_roi = segmentation_roi(image_eq)\n",
    "    \n",
    "    crop_image = crop_image_box(image=image,\n",
    "                                shape=find_center_mask(image_roi),\n",
    "                                margin_pixel=80)\n",
    "    # Detectando bordas\n",
    "    canny_edges = feature.canny(exposure.equalize_hist(crop_image))\n",
    "    sobel_edges = filters.sobel(canny_edges)\n",
    "\n",
    "    # Conectando bordase preenchendo clusters\n",
    "    closed_frame = morphology.closing(sobel_edges, morphology.disk(15))\n",
    "\n",
    "    closed_frame = binarize_image(closed_frame)\n",
    "\n",
    "    closed_frame = find_best_larger_cluster(closed_frame)\n",
    "\n",
    "    return crop_image, ndi.binary_fill_holes(closed_frame)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d53b0acf-9eea-4fca-bf71-d364f0eb9bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rule_of_three_percent_pixels(arr):\n",
    "    \n",
    "    \"\"\"\n",
    "        Essa função calcula a porcentagem de pixels Pretos e Brancos\n",
    "        Essa informação é importante para selecionar imagens válidas para processamentos\n",
    "    \"\"\"\n",
    "    \n",
    "    def co_occurrence(arr):\n",
    "        unique, counts = np.unique(arr, return_counts=True)\n",
    "    \n",
    "        return dict(zip(unique, counts))\n",
    "\n",
    "    def ternary(value):\n",
    "        return 0 if value == None else value\n",
    "        \n",
    "    def binarize_image(arr):\n",
    "        return arr > filters.threshold_minimum(arr)\n",
    "\n",
    "    image_bin = binarize_image(arr)\n",
    "    image_coo = co_occurrence(image_bin)\n",
    "    \n",
    "    true_value = ternary(image_coo.get(True))\n",
    "    false_value = ternary(image_coo.get(False)) \n",
    "\n",
    "    _100 = false_value + true_value\n",
    "    \n",
    "    return dict({\n",
    "        'true_pixels': int((true_value * 100) / _100), \n",
    "        'false_pixels': int((false_value * 100) / _100)\n",
    "    })\n",
    "\n",
    "\n",
    "def check_colision_border(mask):\n",
    "    \"\"\"\n",
    "        Pós processamento\n",
    "    \"\"\"\n",
    "    x, *_ = mask.shape\n",
    "    \n",
    "    left = mask[:1,].flatten()\n",
    "    right = mask[x - 1: x,].flatten()\n",
    "    top = mask[:, : 1].flatten()\n",
    "    bottom = mask[:, x - 1: x].flatten()\n",
    "    \n",
    "    borders_flatten = [left, right, top, bottom]\n",
    "    if np.concatenate(borders_flatten).sum():\n",
    "        return True\n",
    "    \n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "31f7efa3-038a-44b0-818c-7a19c9ae149c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tifffile\n",
    "from glob import glob \n",
    "from tqdm import tqdm \n",
    "import os\n",
    "\n",
    "def runner_v2(bg_image_path,\n",
    "              img_name,\n",
    "              path_out_folder,\n",
    "              path_images_in_folder,\n",
    "              fn_segmentation):\n",
    "\n",
    "    path_images = f'{path_out_folder}/{img_name}/images'\n",
    "    path_masks = f'{path_out_folder}/{img_name}/masks'\n",
    "    \n",
    "    try:\n",
    "        os.makedirs(path_out_folder)\n",
    "    except Exception: pass\n",
    "        \n",
    "    try:\n",
    "        os.makedirs(path_images)\n",
    "        os.makedirs(path_masks)\n",
    "    except Exception: pass\n",
    "\n",
    "    arr_images =  glob(path_images_in_folder + '/*')\n",
    "    background = crop_image_reduce_errors(imread(bg_image_path)[:, :, 0])\n",
    "    \n",
    "    for index, frame_path in enumerate(tqdm(arr_images)):\n",
    "        \n",
    "        image_loaded = tifffile.imread(frame_path)[:, :, 0]\n",
    "        image = crop_image_reduce_errors(image_loaded)\n",
    "\n",
    "        try: percents = rule_of_three_percent_pixels(image) \n",
    "        except Exception: continue\n",
    "\n",
    "        is_image_valid = percents['true_pixels'] > percents['false_pixels']\n",
    "\n",
    "        # Ignora se a imagem for predominantemente preta\n",
    "        if not is_image_valid: continue\n",
    "\n",
    "        # Ignora qualquer error de segmentação e parte para o proximo frame\n",
    "        try:\n",
    "            image_cropped, mask = fn_segmentation(image, background)\n",
    "        except Exception: continue\n",
    "\n",
    "        # Ignora se a mascara colidir com as bordas\n",
    "        if check_colision_border(mask): continue\n",
    "        \n",
    "        imsave(f'{path_images}/{str(index)}.tif', image_cropped)\n",
    "        imsave(f'{path_masks}/{str(index)}.tif', img_as_ubyte(mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "35a55c97-254b-4a82-a341-d5befc3d6b7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 257/257 [01:53<00:00,  2.25it/s]\n"
     ]
    }
   ],
   "source": [
    "runner_v2(bg_image_path='background.tif',\n",
    "          img_name='005',\n",
    "          path_out_folder='results_outs',\n",
    "          path_images_in_folder='dataset/images/005',\n",
    "          fn_segmentation=segmentation_mask_v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c713ef-3045-4bd8-aa3b-04c696568e4f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
